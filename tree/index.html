



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="A Material Design theme for MkDocs">
      
      
      
        <meta name="author" content="Martin Donath">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>Decision Tree - Data Mining A</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
      <script src="../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#decision-tree" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="Data Mining A" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Data Mining A
            </span>
            <span class="md-header-nav__topic">
              Decision Tree
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

<nav class="md-tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href=".." title="Data Mining" class="md-tabs__link md-tabs__link--active">
        Data Mining
      </a>
    
  </li>

      
        
      
        
      
        
      
        
      
        
      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href=".." title="Data Mining A" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Data Mining A
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Data Mining" class="md-nav__link">
      Data Mining
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../kmeans/" title="K-Means Clustering" class="md-nav__link">
      K-Means Clustering
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../getting-started/" title="Getting started" class="md-nav__link">
      Getting started
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../specimen/" title="Program K-Means Clustering" class="md-nav__link">
      Program K-Means Clustering
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../customization/" title="KNN K-Nearest Neighbor" class="md-nav__link">
      KNN K-Nearest Neighbor
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Decision Tree
      </label>
    
    <a href="./" title="Decision Tree" class="md-nav__link md-nav__link--active">
      Decision Tree
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#kelebihan-kekurangan-pohon-keputusan-atau-decision-tree" title="Kelebihan &amp; Kekurangan Pohon Keputusan atau Decision Tree" class="md-nav__link">
    Kelebihan &amp; Kekurangan Pohon Keputusan atau Decision Tree
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#arsitektur-pohon-keputusan" title="Arsitektur Pohon Keputusan" class="md-nav__link">
    Arsitektur Pohon Keputusan
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langkah-langkah-konstruksi-pohon-keputusan-dengan-algoritma-id3" title="Langkah-Langkah Konstruksi Pohon Keputusan dengan Algoritma ID3" class="md-nav__link">
    Langkah-Langkah Konstruksi Pohon Keputusan dengan Algoritma ID3
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#entropy-information-gain" title="Entropy &amp; Information Gain" class="md-nav__link">
    Entropy &amp; Information Gain
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#kelebihan-kekurangan-pohon-keputusan-atau-decision-tree" title="Kelebihan &amp; Kekurangan Pohon Keputusan atau Decision Tree" class="md-nav__link">
    Kelebihan &amp; Kekurangan Pohon Keputusan atau Decision Tree
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#arsitektur-pohon-keputusan" title="Arsitektur Pohon Keputusan" class="md-nav__link">
    Arsitektur Pohon Keputusan
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langkah-langkah-konstruksi-pohon-keputusan-dengan-algoritma-id3" title="Langkah-Langkah Konstruksi Pohon Keputusan dengan Algoritma ID3" class="md-nav__link">
    Langkah-Langkah Konstruksi Pohon Keputusan dengan Algoritma ID3
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#entropy-information-gain" title="Entropy &amp; Information Gain" class="md-nav__link">
    Entropy &amp; Information Gain
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="decision-tree"><strong>DECISION TREE</strong><a class="headerlink" href="#decision-tree" title="Permanent link">&para;</a></h1>
<p>Algoritma ID3 merupakan algoritma yang dipergunakan untuk membangun sebuah decision tree atau pohon keputusan. Algoritma ini ditemukan oleh J. Ross Quinlan (1979), dengan memanfaatkan Teori Informasi atau Information Theory milik Shanon. ID3 sendiri merupakan singkatan dari Iterative Dichotomiser 3.</p>
<p>Decision tree menggunakan struktur hierarki untuk pembelajaran supervised. Proses dari decision tree dimulai dari root node hingga leaf node yang dilakukan secara rekursif. Di mana setiap percabangan menyatakan suatu kondisi yang harus dipenuhi dan pada setiap ujung pohon menyatakan kelas dari suatu data.</p>
<p>Proses dalam decision tree yaitu mengubah bentuk data (tabel) menjadi model pohon (tree) kemudian mengubah model pohon tersebut menjadi aturan (rule).</p>
<p>Dengan pendekatan ini, salah satu kelemahan algoritma dari decision tree, adalah faktor skalabilitas dimana algoritma tersebut hanya dapat digunakan untuk menangani sampel-sampel yang dapat disimpan secara keseluruhan dan pada waktu yang bersamaan di memori.</p>
<p>Algoritma ID3 tidak pernah melakukan backtracking untuk merevisi keputusan pemilihan attribute yang telah dilakukan sebelumnya. ID3 hanya menangani nilai-nilai attribute yang sedikit dan diskret, tetapi algoritma modifikasinya, algoritma C4.5 (1993), selanjutnya mampu menangani nilai attribute kontinu.</p>
<h4 id="kelebihan-kekurangan-pohon-keputusan-atau-decision-tree">Kelebihan &amp; Kekurangan Pohon Keputusan atau Decision Tree<a class="headerlink" href="#kelebihan-kekurangan-pohon-keputusan-atau-decision-tree" title="Permanent link">&para;</a></h4>
<p>Metode pohon keputusan mempunyai beberapa kelebihan, diantaranya sebagai berikut :</p>
<ol>
<li>Daerah pengambilan keputusan yang sebelumnya kompleks dan sangat global, dapat diubah menjadi simple dan spesifik.</li>
<li>Eliminasi perhitungan-perhitungan yang tidak diperlukan, karena ketika menggunakan metode pohon keputusan maka contoh diuji hanya berdasarkan kriteria atau kelas-kelas tertentu.</li>
<li>Fleksibel untuk memilih fitur dari internal node yang berbeda, fitur yang terpilih akan membedakan suatu kriteria dibandingkan kriteria yang lain dalam node yang sama.</li>
<li>Metode pohon keputusan dapat menghindari munculnya permasalahan ini dengan menggunakan kriteria yang jumlahnya lebih sedikit pada setiap node internal tanpa banyak mengurangi kualitas keputusan yang dihasilkan.</li>
</ol>
<p>Selain kelebihan dari pohon keputusan, terdapat juga beberapa kekurangan dari pohon keputusan, diantaranya sebagai berikut :</p>
<ol>
<li>Terjadi overlap terutama ketika kelas-kelas dan kriteria yang digunakan jumlahnya sangat banyak. Hal tersebut juga dapat menyebabkan meningkatnya waktu pengambilan keputusan dan jumlah memori yang diperlukan.</li>
<li>Pengakumulasian jumlah eror dari setiap tingkat dalam sebuah pohon keputusan yang besar.</li>
<li>Kesulitan dalam mendesain pohon keputusan yang optimal</li>
<li>Hasil kualitas keputusan yang didapatkan dari metode pohon keputusan sangat tergantung pada bagaimana pohon tersebut didesain.</li>
</ol>
<h4 id="arsitektur-pohon-keputusan"><strong>Arsitektur Pohon Keputusan</strong><a class="headerlink" href="#arsitektur-pohon-keputusan" title="Permanent link">&para;</a></h4>
<p>Arsitektur pohon keputusan dibuat menyerupai bentuk pohon, dimana pada umumnya sebuah pohon terdapat akar (root), cabang dan daun (leaf). Pada pohon keputusan juga terdiri  dari tiga bagian sebagai berikut :</p>
<p>a. <strong>Root node</strong> atau node akar merupakan node yang terletak paling atas dari suatu pohon.</p>
<p>b. <strong>Internal Node</strong> ini merupakan node percabangan, dimana pada node ini hanya terdapat satu input dan mempunyai minimal dua output.</p>
<p>c. <strong>Leaf Node</strong> ini merupakan node akhir, hanya memiliki satu input, dan tidak memiliki output. Pada pohon keputusan setiap leaf node menandai label kelas.</p>
<p>Pada pohon keputusan di setiap percabangan menyatakan kondisi yang harus dipenuhi dan tiap ujung pohon menyatakan nilai kelas data. Gambar berikut merupakan bentuk arsitektur pohon keputusan.</p>
<p><img alt="" src="../assets/images/Arsitektur-Pohon-Keputusan-2.jpg" /></p>
<h4 id="langkah-langkah-konstruksi-pohon-keputusan-dengan-algoritma-id3"><strong>Langkah-Langkah Konstruksi Pohon Keputusan dengan Algoritma ID3</strong><a class="headerlink" href="#langkah-langkah-konstruksi-pohon-keputusan-dengan-algoritma-id3" title="Permanent link">&para;</a></h4>
<p>Adapun langkah-langkah dalam konstruksi pohon keputusan adalah sebagai berikut :</p>
<p><strong>Langkah 1 :</strong> Pohon dimulai dengan sebuah simpul yang mereperesentasikan sampel data pelatihan yaitu dengan membuat simpul akar.</p>
<p><strong>Langkah 2 :</strong> Jika semua sampel berada dalam kelas yang sama, maka simpul ini menjadi daun dan dilabeli menjadi kelas. Jika tidak, information gain akan digunakan untuk memilih atribut terbaik dalam memisahkan data sampel menjadi kelas-kelas individu.</p>
<p><strong>Langkah 3 :</strong> Cabang akan dibuat untuk setiap nilai pada atribut dan data sampel akan dipartisi lagi.</p>
<p><strong>Langkah 4 :</strong> Algoritma ini menggunakan proses rekursif untuk membentuk pohon keputusan pada setiap data partisi. Jika sebuah atribut sduah digunakan disebuah simpul, maka atribut ini tidak akan digunakan lagi di simpul anak-anaknya.</p>
<p><strong>Langkah 5 :</strong> Proses ini berhenti jika dicapai kondisi seperti berikut :</p>
<p>– Semua sampel pada simpul berada di dalam satu kelas</p>
<p>– Tidak ada atribut lainnya yang dapat digunakan untuk mempartisi sampel lebih lanjut. Dalam hal ini akan diterapkan suara terbanyak. Ini berarti mengubah sebuah simpul menjadi daun dan melabelinya dnegan kelas pada suara terbanyak.</p>
<h4 id="entropy-information-gain"><strong>Entropy &amp; Information Gain</strong><a class="headerlink" href="#entropy-information-gain" title="Permanent link">&para;</a></h4>
<p>Algoritma pada metode ini menggunakan konsep dari entropi. Konsep Entropi yang digunakan untuk mengukur “seberapa informatifnya” sebuah node (yang biasanya disebut seberapa baiknya).</p>
<p>Entropi(S) = 0, jika semua contoh pada S berada dalam kelas yang sama.
Entroiy(S) = 1, jika jumlah contoh positif dan jumlah contoh negatif dalam S adalah sama.
0 &lt; Entropi(S) &lt; 1, jika jumlah contoh positif dan negatif dalam S tidak sama.</p>
<p><img alt="" src="../assets/images/entropi.jpg" /></p>
<p>Dimana:
• <em>S</em> adalah himpunan (dataset) kasus
• <em>k</em> adalah banyaknya partisi <em>S</em>
• <em>pj</em> adalah probabilitas yang di dapat dari Sum(Ya) dibagi Total Kasus.</p>
<p>Setelah mendapat nilai entropi, pemilihan atribut dilakukan dengan nilai information gain terbesar.</p>
<p><img alt="" src="../assets/images/gain-decision-tree.jpg" /></p>
<p>Dimana:
S = ruang (data) sample yang digunakan untuk training.
A = atribut.
|Si| = jumlah sample untuk nilai V.
|S| = jumlah seluruh sample data.
Entropi(Si) = entropy untuk sample-sample yang memiliki nilai <em>i</em></p>
<p>Classification Tree ini menggunakan data :</p>
<p><strong>pima-indians-diabetes.cvs</strong> (bisa di unduh : <a href="https://www.kaggle.com/uciml/pima-indians-diabetes-database">https://www.kaggle.com/uciml/pima-indians-diabetes-database</a>).</p>
<p>Data tersebut jadikan satu folder dengan file <strong>pyCharm</strong> atau programnya.</p>
<p><img alt="" src="../assets/images/data.jpg" /></p>
<p><strong>Langkah 1 :</strong></p>
<p>Sebelum menuliskan <strong>source code</strong>, kita harus menginstall <strong>library</strong> terlebih dahulu. Dalam implementasi <strong>Classification Tree</strong>, perlu <strong>library</strong> <strong>pandas</strong> dan <strong>scikit_learn</strong>. Cara menginstallnya, ketikan code dibawah ini kedalam <strong>command prompt</strong> :</p>
<pre class="codehilite"><code>pip install pandas
pip install scikit-learn</code></pre>

<p><strong>Langkah 2 :</strong></p>
<p>Setelah <strong>libary</strong> terpasang, saatnya kita mulai mengetikan programnya. Pertama adalah <strong>load libaries**atau impor, seperti pada **source code</strong> dibawah ini :</p>
<pre class="codehilite"><code>#load libaries

import pandas as pd
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier #Import Decision Tree Classifier
from sklearn.model_selection import train_test_split #Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation</code></pre>

<p>Menjalankan <strong>library</strong> yang telah kita pasang atau install melalui <strong>command prompt</strong>. (langkah 1)</p>
<p>Import Decision Tree Classifier : Impor Klasifikasi Pohon Keputusan</p>
<p>Import train_test_split function : Impor fungsi train_test_split</p>
<p>Import scikit-learn metrics module for accuracy calculation : Import scikit-learn metrik untuk modul perhitungan akurasi</p>
<p><strong>Langkah 3 :</strong></p>
<p>Tahap selanjutnya adalah <strong>col_names</strong> , memberikan nama pada tabel di dalamdata :</p>
<pre class="codehilite"><code>col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']</code></pre>

<p><strong>Langkah 4</strong> :</p>
<p>Memasuki langkah keempat adalah tahap <strong>load dataset</strong> (memuat database). Bisa ketikan **source code**seperti pada gambar dibawah ini :</p>
<pre class="codehilite"><code># load dataset
pima = pd.read_csv("pima-indians-diabetes.csv", header=None, names=col_names)
pima.head()</code></pre>

<p><strong>Langkah 5 :</strong></p>
<p>Selanjutnya adalah <strong>Feature Selection</strong> (pemilihan fitur), tahap <strong>split dataset in features and target variable</strong> atau memisahkan dataset dalam fitur dan variabel target. Dengan <strong>source code</strong> seperti berikut :</p>
<pre class="codehilite"><code>#split dataset in features and target variable
feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']
X = pima[feature_cols] # Features
y = pima.label # Target variable</code></pre>

<p><strong>Langkah 6 :</strong></p>
<p>Tahap kelima adalah memasukan <strong>Split dataset into training set and test set</strong> yaitu memisahkan dataset dalam fitur dan variabel target. Tahap ini masih sama yaitu tahap <strong>Feature Selection</strong> :</p>
<pre class="codehilite"><code># Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test</code></pre>

<p><a href="https://github.com/squidfunk/mkdocs-material/issues/70">#70</a>% training and 30% test : 70% data dari <strong>bill_authentication.csv</strong> adlah data training dan 30% dalah data tes</p>
<p><strong>Langkah 7 :</strong></p>
<p>Selanjutnya adalah tahap <strong>Create Decision Tree classifer object</strong>, yaitu tahap membuat objek classifier <strong>Desicion tree</strong>. Berikut adalah <strong>Source code</strong> nya :</p>
<pre class="codehilite"><code># Create Decision Tree classifer object
clf_gini = DecisionTreeClassifier()</code></pre>

<p>**Langkah 8 : **</p>
<p>Tahap ketujuh adalah proses <strong>Train Decision Tree Classifer</strong>, dengan cara yang sama, memasukkan <strong>source code</strong> dibawah ini :</p>
<pre class="codehilite"><code># Train Decision Tree Classifer
clf_gini = clf_gini.fit(X_train,y_train)</code></pre>

<p><strong>Langkah 9 :</strong></p>
<p>Kemudian tahap prediksi pada dataset yang diuji, atau biasa disebut dengan <strong>Predict the response for test dataset</strong> :</p>
<pre class="codehilite"><code>#Predict the response for test dataset
y_pred = clf_gini.predict(X_test)</code></pre>

<p><strong>Langkah 10 :</strong></p>
<p>Tahap terakhir adalah model <strong>accuracy</strong>. Dimana pada tahap ini dicek <strong>accuracy</strong> pada data tersebut :</p>
<pre class="codehilite"><code># Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred));</code></pre>

<p><strong>[ Hasil Implementasi ]</strong></p>
<p>Dan berikut adalah hasil dari <strong>Algorithm Classification tree</strong> :</p>
<pre class="codehilite"><code>Accuracy: 0.6623376623376623

Process finished with exit code 0</code></pre>

<p>Jadi, <strong>accuracy</strong> dari <strong>Algorithm Classification tree</strong> dengan data : <strong>bill_authentication.csv</strong> adalah 6,6%. Sehingga dapat di ambil kesimpulan bahwa data <strong>accurasy</strong> tersebut standart.</p>
<p>Referensi :</p>
<p>Sumber: <a href="https://medium.com/">https://medium.com</a></p>
<p>Sumber : <a href="https://informatikalogi.com/">https://informatikalogi.com/</a></p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../customization/" title="KNN K-Nearest Neighbor" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                KNN K-Nearest Neighbor
              </span>
            </div>
          </a>
        
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2016 - 2019 Moch. Rofik  
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="None" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="https://github.com" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://twitter.com" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://linkedin.com" class="md-footer-social__link fa fa-linkedin"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.8c0d971c.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
  </body>
</html>